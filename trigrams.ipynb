{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUCTION\n",
    "\n",
    "This project aims to build a trigram model using text from books available on Project Gutenberg. A trigram is only a group of three characters in a row from a piece of text. Counting how many times each of these three-character sequences shows up, we can start to see patterns in how the English languages is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading text books from Project Gutenberg in UTF8 format \n",
    "\n",
    "https://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspaces/Emerging-Technologies/Data/Frankenstein.txt' ,'r', encoding='utf-8') as file: #going to the file path and opening the book in read mode, using UTF-8 encoding\n",
    "    text = file.read() #the 'with' ensures the file is closed after reading\n",
    "\n",
    "# Print the frist 500 characters to check if its working\n",
    "# print(\"text sample\", text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT PROCESSING\n",
    "\n",
    "re - Regular Expression Operations \n",
    "\n",
    "https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries and Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Function to preprocess text by removing unwanted characters and converting to uppercase\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text)  # Keep only letters, spaces, and periods\n",
    "    return cleaned_text.upper()  # Convert all letters to uppercase\n",
    "\n",
    "# Function to create a trigram model from a given text\n",
    "def create_trigram_model(text):\n",
    "    trigram_counts = defaultdict(int)\n",
    "    for i in range(len(text) - 2):  # Looping through each character, stopping two characters from the end\n",
    "        trigram = text[i:i+3]  # Extract three consecutive characters as a trigram\n",
    "        trigram_counts[trigram] += 1  # Count each trigram\n",
    "    return trigram_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIGRAM DESIGN FOR A SINGLE TEXT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trigram is a sequence of three characters, so we need to go to through the processe text, grab three characters at a time, and count the number of times they occur. In order to do this we use Python's, defaultdict from the collections module. \n",
    "\n",
    "The defaultdict(int) creates a dictionary where each trigram has a default value of 0.\n",
    "\n",
    "When we find a new trigram, its count starts at 0, and we can increment it directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram: IT  | Count: 2\n",
      "Trigram: T I | Count: 3\n",
      "Trigram:  IS | Count: 2\n",
      "Trigram: IS  | Count: 1\n",
      "Trigram: S W | Count: 1\n",
      "Trigram:  WH | Count: 1\n",
      "Trigram: WHA | Count: 1\n",
      "Trigram: HAT | Count: 1\n",
      "Trigram: AT  | Count: 1\n",
      "Trigram:  IT | Count: 1\n",
      "Trigram: IS. | Count: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict # Importing dictionary from collections module to create a dictionary with default values\n",
    "\n",
    "# Defining a function to create a trigram model from the input text\n",
    "def create_trigram_model(text):\n",
    "    # Create a dictionary with a default value of 0 which will store the counts of each trigram\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the text, stopping 2 characters before the end to form trigrams\n",
    "    for i in range(len(text)-2):\n",
    "\n",
    "        # Extract a trigram starting at position 'i'\n",
    "        trigram = text[i:i+3]\n",
    "\n",
    "        #increment the count of the trigram in the dictionary\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    # Return the dictionary containing \n",
    "    return trigram_counts\n",
    "\n",
    "# Using the function provided in README\n",
    "sample_text = \"IT IS WHAT IT IS.\"\n",
    "\n",
    "#Apply the trigram model function to the proccessed text and store the result in trigrams\n",
    "trigram_model = create_trigram_model(sample_text)\n",
    "\n",
    "# Printing the trigram counts\n",
    "for trigram, count in trigram_model.items():\n",
    "    print(f\"Trigram: {trigram} | Count: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every trigram is a sequence of three chars, extracted by iterating throught the text. For each we just update the trigram count in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIGRAM DESIGN FOR MULTIPLE TEXTS, LOADING TEXT FILES, AND PROCESSING THEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique trigrams: 8698\n",
      "Sample trigrams and counts:\n",
      "'THE': 44141\n",
      "'HE ': 34073\n",
      "'E P': 3719\n",
      "' PR': 3931\n",
      "'PRO': 2597\n",
      "'ROJ': 472\n",
      "'OJE': 472\n",
      "'JEC': 920\n",
      "'ECT': 3174\n",
      "'CT ': 1469\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "texts = ['/workspaces/Emerging-Technologies/Data/Frankenstein.txt',\n",
    "         '/workspaces/Emerging-Technologies/Data/mobydick.txt',\n",
    "         '/workspaces/Emerging-Technologies/Data/Pride.txt',\n",
    "         '/workspaces/Emerging-Technologies/Data/Romeo.txt',\n",
    "         '/workspaces/Emerging-Technologies/Data/Scarlet.txt',\n",
    "         '/workspaces/Emerging-Technologies/Data/What to do at the moment.txt']\n",
    "\n",
    "# Initializing a defaultdict to store multiple trigram counts from all texts\n",
    "multiple_trigram_model = defaultdict(int)\n",
    "\n",
    "# Looping through each file in the list\n",
    "for filename in texts:\n",
    "    # Opening current file in read mode with UTF-9 encoding\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read() # Reading the entire content of the file\n",
    "        \n",
    "        # Cleans the text and converts it to uppercase\n",
    "        processed_text = preprocess_text(text)  \n",
    "        trigram_model = create_trigram_model(processed_text)  # Assuming create_trigram_model is defined\n",
    "\n",
    "        # Updates the combined trigram model with counts from the current file\n",
    "        for trigram, count in trigram_model.items():\n",
    "            multiple_trigram_model[trigram] += count\n",
    "\n",
    "# Printing the number of unique trigrams\n",
    "print(f\"Unique trigrams: {len(multiple_trigram_model)}\")\n",
    "\n",
    "# Printing a sample of 10 trigrams and their counts\n",
    "print(\"Sample trigrams and counts:\")\n",
    "for trigram, count in list(multiple_trigram_model.items())[:10]:\n",
    "    print(f\"'{trigram}': {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SORTING TRIGRAMS BY FREQUENCY\n",
    "\n",
    "Here we sort the trigrams in the multiple trigram model developed by their frequency in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent trigrams:\n",
      "' TH': 52319\n",
      "'THE': 44141\n",
      "'HE ': 34073\n",
      "'ED ': 20152\n",
      "'ND ': 19696\n",
      "'AND': 19694\n",
      "' AN': 19535\n",
      "' OF': 17461\n",
      "'ING': 16840\n",
      "'ER ': 16093\n"
     ]
    }
   ],
   "source": [
    "# Sort trigrams by frequency\n",
    "sorted_trigrams = sorted(multiple_trigram_model.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 10 most frequent trigrams\n",
    "print(\"Top 10 most frequent trigrams:\")\n",
    "for trigram, count in sorted_trigrams[:10]:\n",
    "    print(f\"'{trigram}': {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS AND ANALYSIS SO FAR\n",
    "\n",
    "Now created this trigram model using multiple text files.\n",
    "\n",
    "In this Trigram Model for multiple texts the code reads each text file, processes the text to remove unwanted characters and conver it to uppercase, and then counts how many times the characters are repeated using a 'defaultdict' called 'multiple_trigram_model'.\n",
    "\n",
    "Process Involves\n",
    "\n",
    "1 - Reading files\n",
    "\n",
    "2 - Text preprocessing ( text is cleaned )\n",
    "\n",
    "3 - Trigram counting ( 'create_trigram_model' functions counts the number of times each trigram occurs in the cleaned text )\n",
    "\n",
    "4 - Results ( Each file's trigram counts are added to the overall trigram model )\n",
    "\n",
    "After processing all files we print the number of unique trigrams and a sample of 10 trigrams with their number of occurences.\n",
    "\n",
    "Sorted the trigrams in 'multiple_trigram_model' by their frequency in descending order. This allows us to identify the top 10 most common trigrams across all files, which are printed in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 2: THIRD-ORDER LETTER APPROXIMATION GENERATION\n",
    "\n",
    "In this task using the trigram model created in Task 1 we will try to use it to generate a string of 10,000 characters. We start with the initial string \"TH\", and generate each subsequent character by looking at the previous two caracters.\n",
    "For eac pair of characters (bigram), we find all trigrams in the model that start with those two characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Function to preprocess text by removing unwanted characters and converting to uppercase\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text)  # Keeping only letters, spaces, and periods\n",
    "    return cleaned_text.upper()  # Retrieving all letters to uppercase\n",
    "\n",
    "# Function to create a trigram model from a given text\n",
    "def create_trigram_model(text):\n",
    "    trigram_counts = defaultdict(int)\n",
    "    for i in range(len(text) - 2):  # Looping through each character, stopping two characters from the end\n",
    "        trigram = text[i:i+3]  # Extracting three consecutive characters as a trigram\n",
    "        trigram_counts[trigram] += 1  # Counting each trigram\n",
    "    return trigram_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTING POSSIBLE TRIGRAMS BASED ON BIGRAM\n",
    "\n",
    "In each iteration, we use the last two characters of the generated text (bigram) to find all trigrams in the model that starts with these characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique trigrams in model: 8698\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    '/workspaces/Emerging-Technologies/Data/Frankenstein.txt',\n",
    "    '/workspaces/Emerging-Technologies/Data/mobydick.txt',\n",
    "    '/workspaces/Emerging-Technologies/Data/Pride.txt',\n",
    "    '/workspaces/Emerging-Technologies/Data/Romeo.txt',\n",
    "    '/workspaces/Emerging-Technologies/Data/Scarlet.txt',\n",
    "    '/workspaces/Emerging-Technologies/Data/What to do at the moment.txt'\n",
    "]\n",
    "\n",
    "# Initializing a defaultdict to store the combined trigram model\n",
    "multiple_trigram_model = defaultdict(int)\n",
    "\n",
    "# Looping through each file, read, preprocess, and update trigram counts\n",
    "for filename in texts:\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        processed_text = preprocess_text(text)  # Clean and standardize text\n",
    "        trigram_model = create_trigram_model(processed_text)  # Counting trigrams in text\n",
    "        \n",
    "        # Combining the trigrams from each file into the overall model\n",
    "        for trigram, count in trigram_model.items():\n",
    "            multiple_trigram_model[trigram] += count\n",
    "\n",
    "# Checking the number of unique trigrams\n",
    "print(f\"Unique trigrams in model: {len(multiple_trigram_model)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEIGHTED RANDOM SELECTION OF NEXT CHARACTER\n",
    "\n",
    "Using the counts of each possible trigram as weights, select the next probably character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample generated text (100 characters):\n",
      "THIND DUCH HE WICTICHME OF HUSIGHADDEEM ITHER VE PAINS WILLOFF NOW SHUSTIOR HOU ALED RE THE COMALE A\n"
     ]
    }
   ],
   "source": [
    "# Function to generate text based on the trigram model\n",
    "def generate_text(trigram_model, length=10000, start=\"TH\"):\n",
    "    \n",
    "    generated_text = start  # Start with initial seed\n",
    "    while len(generated_text) < length:\n",
    "        # Get the last two characters to form the current bigram\n",
    "        bigram = generated_text[-2:]\n",
    "        \n",
    "        # Finding all trigrams that start with this bigram\n",
    "        possible_trigrams = {tri: count for tri, count in trigram_model.items() if tri.startswith(bigram)}\n",
    "        \n",
    "        # Breaking if no possible trigrams are found for the current bigram\n",
    "        if not possible_trigrams:\n",
    "            break\n",
    "\n",
    "        # Extracting the third character of each trigram and its frequency as weights\n",
    "        third_chars = [tri[2] for tri in possible_trigrams]\n",
    "        weights = list(possible_trigrams.values())\n",
    "\n",
    "        # Randomly selecting the next character based on the weights\n",
    "        next_char = random.choices(third_chars, weights=weights, k=1)[0]\n",
    "        \n",
    "        # Appending the selected character to the generated text\n",
    "        generated_text += next_char\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Sample text of 100 characters\n",
    "sample_text = generate_text(multiple_trigram_model, length=100)\n",
    "print(\"Sample generated text (100 characters):\")\n",
    "print(sample_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINALIZING THE FUNCTION AND GENERATING TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text Sample (first 500 characters):\n",
      "THER WOREAS FIED PLE CARE THISPEACK ITY OT I DED AN AND AGODS THE VERE.TAINALLY MANDAUT FOR ANDAM AN LEMAIREPOIN DUS AT TH ING IND AND LID SETHEHER. BENTESID HEYMENTS RE OF LINIS SHEHE PECT MADUALLINVENE MING AL A THOURSOLLARL NOBSUAGE SHE THROJECTINTRANIMEEN ATARAT HAD IS. THERIN THER INGS ONT LETS PROU HILL PAR DINGS OF IN. THEITHELLY FORLREGIT SEEM OR POING OFTH SOLLY AND MAT WITHE WORK AS FULD NORES AND ALLOOD RIGHTES. IND DREARTLE AN IN TO BULD LOWS WIM UND HE A BYTHE ING AS HATING ARCIRE W\n"
     ]
    }
   ],
   "source": [
    "# Generating a string of 10,000 characters\n",
    "generated_string = generate_text(multiple_trigram_model, length=10000)\n",
    "\n",
    "# Printing the first 500 characters to check the output\n",
    "print(\"Generated Text Sample (first 500 characters):\")\n",
    "print(generated_string[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK2 REVIEW\n",
    "\n",
    "It starts with \"TH\" and generates characters based on the previous two.\n",
    "\n",
    "It uses the trigram model to make probabilistic selections.\n",
    "\n",
    "It stops at the desired length, or when there are no available trigrams for the bigram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 3 ANALYZING THE  MODEL\n",
    "\n",
    "In this task, we analyze the text generated in Task2 by determining the percentage of valid English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample English words from words.txt: ['ACKNOWLEDGMENT', 'OVERWRITE', 'DECEIVES', 'PHILOSOPHIZES', 'ABASH', 'ABDUCTIONS', 'REPLETE', 'UNANIMITY', 'BUSHES', 'DAMPING']\n"
     ]
    }
   ],
   "source": [
    "with open('/workspaces/Emerging-Technologies/Data/words.txt', 'r') as file:\n",
    "    english_words = set(word.strip().upper() for word in file)  # Use a set for fast lookup\n",
    "\n",
    "# Checking a few sample words to confirm they loaded correctly\n",
    "print(\"Sample English words from words.txt:\", list(english_words)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Code cell reads words.txt and stores each word in englis_words, a set that enables fast lookup. It also converts each single word to uppercase for case-insensitive comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTING WORDS FROM GENERATED TEXT AND CHECK AVAILABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in generated text: 1680\n",
      "Valid English words: 603\n",
      "Percentage of valid English words: 35.89%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Extractin words from the generated text by splitting on non-letter characters\n",
    "words_in_generated_text = re.findall(r'\\b[A-Z]+\\b', generated_string)  # Extract only alphabetic \"words\"\n",
    "\n",
    "# Counting the number of valid English words in the generated text\n",
    "valid_word_count = sum(1 for word in words_in_generated_text if word in english_words)\n",
    "total_word_count = len(words_in_generated_text)\n",
    "\n",
    "# Calculating the percentage of valid English words\n",
    "valid_word_percentage = (valid_word_count / total_word_count) * 100 if total_word_count > 0 else 0\n",
    "\n",
    "# Outputing results\n",
    "print(f\"Total words in generated text: {total_word_count}\")\n",
    "print(f\"Valid English words: {valid_word_count}\")\n",
    "print(f\"Percentage of valid English words: {valid_word_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.findall extracts all alphabetic sequences from generated_sring. This makes sure that only\"words\" (alphabetic sequences) are choosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
